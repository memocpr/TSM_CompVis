{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Initializes notebook: inline plots, adds src/ to Python path, sets IMAGES_DIR to images1/, and prints the path.",
   "id": "7e77f6bfe2bbf30a"
  },
  {
   "cell_type": "code",
   "id": "5eef0d73304fe920",
   "metadata": {},
   "source": [
    "# Initial setup: paths and imports\n",
    "%matplotlib inline\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "SRC_DIR = ROOT / 'src'\n",
    "if SRC_DIR.exists() and str(SRC_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC_DIR))  # allow `import ...` from local src/\n",
    "\n",
    "IMAGES_DIR = ROOT / 'images1'\n",
    "print('Ready. Images path:', IMAGES_DIR)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Lists JPGs in IMAGES_DIR and displays the first one (RGB) with title and shape.",
   "id": "dac764f682bcb902"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Preview a sample image (robust if setup cell wasn't run)\n",
    "from pathlib import Path\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "IMAGES_DIR = globals().get('IMAGES_DIR', Path.cwd() / 'images1')\n",
    "\n",
    "image_files = sorted(IMAGES_DIR.glob('*.jpg'))\n",
    "assert image_files, f'No .jpg images found in {IMAGES_DIR}'\n",
    "\n",
    "img_path = image_files[0]\n",
    "img = io.imread(img_path)  # RGB\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.title(img_path.name)\n",
    "plt.axis('off')\n",
    "print('Image shape:', img.shape)"
   ],
   "id": "bf5095d1b648e0e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Binarize the sample image: convert to grayscale, lightly blur, apply Otsu threshold, and show original vs binary.",
   "id": "7ea87e434c4b44a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Binarize image: grayscale -> blur -> Otsu threshold\n",
    "from pathlib import Path\n",
    "from skimage import io\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import gaussian, threshold_otsu\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# reuse loaded image if present; otherwise load first jpg\n",
    "if 'img' not in globals():\n",
    "    IMAGES_DIR = globals().get('IMAGES_DIR', Path.cwd() / 'images1')\n",
    "    img_path = sorted(IMAGES_DIR.glob('*.jpg'))[0]\n",
    "    img = io.imread(img_path)\n",
    "\n",
    "gray = rgb2gray(img)              # 0..1 float\n",
    "blur = gaussian(gray, sigma=1.0)  # light denoise\n",
    "t = threshold_otsu(blur)\n",
    "bw = blur < t                     # ink is dark -> True\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "axes[0].imshow(img);  axes[0].set_title('Original');  axes[0].axis('off')\n",
    "axes[1].imshow(bw, cmap='gray'); axes[1].set_title(f'Binarized (t={t:.3f})'); axes[1].axis('off')\n",
    "print('gray shape:', gray.shape, 'threshold:', t)"
   ],
   "id": "f11fdf16f1e866d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Clean the binary mask by removing small components (noise); visualize before vs. after.",
   "id": "8c360ee0ff2b6d64"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Clean binary mask: remove tiny components (noise)\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.morphology import remove_small_objects\n",
    "\n",
    "# fallbacks if earlier cells weren't run\n",
    "if 'img' not in globals():\n",
    "    from pathlib import Path\n",
    "    from skimage import io\n",
    "    IMAGES_DIR = globals().get('IMAGES_DIR', Path.cwd() / 'images1')\n",
    "    img = io.imread(sorted(IMAGES_DIR.glob('*.jpg'))[0])\n",
    "if 'bw' not in globals():\n",
    "    from skimage.color import rgb2gray\n",
    "    from skimage.filters import gaussian, threshold_otsu\n",
    "    gray = rgb2gray(img)\n",
    "    t = threshold_otsu(gaussian(gray, 1.0))\n",
    "    bw = gray < t\n",
    "\n",
    "clean = remove_small_objects(bw, min_size=150)  # adjust if needed\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "axes[0].imshow(bw, cmap='gray');    axes[0].set_title('Binary');  axes[0].axis('off')\n",
    "axes[1].imshow(clean, cmap='gray'); axes[1].set_title('Cleaned'); axes[1].axis('off')"
   ],
   "id": "9d698a3470723a3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Label connected components on the cleaned mask and draw bounding boxes over the original image.",
   "id": "7b05423d352185eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Fix: compute boxes using .start/.stop from find_objects slices\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from scipy import ndimage as ndi\n",
    "from skimage import io\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import gaussian, threshold_otsu\n",
    "from pathlib import Path\n",
    "\n",
    "# fallbacks if earlier cells weren't run\n",
    "if 'img' not in globals():\n",
    "    IMAGES_DIR = globals().get('IMAGES_DIR', Path.cwd() / 'images1')\n",
    "    img = io.imread(sorted(IMAGES_DIR.glob('*.jpg'))[0])\n",
    "if 'clean' not in globals():\n",
    "    gray = rgb2gray(img)\n",
    "    blur = gaussian(gray, 1.0)\n",
    "    clean = blur < threshold_otsu(blur)\n",
    "\n",
    "min_size = 150\n",
    "\n",
    "labels, num = ndi.label(clean)\n",
    "slices = ndi.find_objects(labels)\n",
    "areas = np.bincount(labels.ravel())  # area per label (index 0 is background)\n",
    "\n",
    "boxes = []\n",
    "for i, slc in enumerate(slices, start=1):  # labels 1..num\n",
    "    if slc is None:\n",
    "        continue\n",
    "    r0, r1 = slc[0].start, slc[0].stop\n",
    "    c0, c1 = slc[1].start, slc[1].stop\n",
    "    if areas[i] < min_size:\n",
    "        continue\n",
    "    boxes.append((r0, c0, r1, c1))\n",
    "\n",
    "boxes.sort(key=lambda b: b[1])  # left-to-right\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.imshow(img)\n",
    "for r0, c0, r1, c1 in boxes:\n",
    "    ax.add_patch(Rectangle((c0, r0), c1 - c0, r1 - r0,\n",
    "                           fill=False, edgecolor='lime', linewidth=2))\n",
    "ax.set_title(f'Components (SciPy): {len(boxes)}')\n",
    "ax.axis('off')\n",
    "print('Detected components:', len(boxes))"
   ],
   "id": "da0ab70124203172",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Extract component crops, pad to square, resize to 28×28, and display them in reading order.",
   "id": "f7c4487925d2bc33"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T08:57:52.469210Z",
     "start_time": "2025-10-27T08:57:40.604630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract crops from boxes, pad to square, resize to 28x28, show grid\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "from pathlib import Path\n",
    "\n",
    "# fallbacks\n",
    "if 'img' not in globals():\n",
    "    from skimage import io\n",
    "    IMAGES_DIR = globals().get('IMAGES_DIR', Path.cwd() / 'images1')\n",
    "    img = io.imread(sorted(IMAGES_DIR.glob('*.jpg'))[0])\n",
    "if 'gray' not in globals():\n",
    "    gray = rgb2gray(img)\n",
    "\n",
    "# if boxes missing, compute from clean mask quickly\n",
    "if 'boxes' not in globals():\n",
    "    from scipy import ndimage as ndi\n",
    "    from skimage.filters import gaussian, threshold_otsu\n",
    "    blur = gaussian(gray, 1.0)\n",
    "    clean = blur < threshold_otsu(blur)\n",
    "    labels, _ = ndi.label(clean)\n",
    "    slices = ndi.find_objects(labels)\n",
    "    areas = np.bincount(labels.ravel())\n",
    "    min_size = 150\n",
    "    boxes = []\n",
    "    for i, slc in enumerate(slices, start=1):\n",
    "        if slc is None or areas[i] < min_size:\n",
    "            continue\n",
    "        r0, r1 = slc[0].start, slc[0].stop\n",
    "        c0, c1 = slc[1].start, slc[1].stop\n",
    "        boxes.append((r0, c0, r1, c1))\n",
    "\n",
    "# sort reading order: top-to-bottom then left-to-right\n",
    "if boxes:\n",
    "    med_h = np.median([b[2]-b[0] for b in boxes]) or 1\n",
    "    row_h = max(1, int(0.6 * med_h))\n",
    "    boxes = sorted(boxes, key=lambda b: (b[0] // row_h, b[1]))\n",
    "\n",
    "def crop_norm(g, b, out=28, pad=2):\n",
    "    r0, c0, r1, c1 = b\n",
    "    crop = g[r0:r1, c0:c1]\n",
    "    # trim empty margins using a simple threshold\n",
    "    thr = np.percentile(crop, 80)  # paper is bright\n",
    "    mask = crop < thr\n",
    "    if mask.any():\n",
    "        rr = np.where(mask.any(axis=1))[0]\n",
    "        cc = np.where(mask.any(axis=0))[0]\n",
    "        crop = crop[rr.min():rr.max()+1, cc.min():cc.max()+1]\n",
    "    # pad to square (white background ~1.0)\n",
    "    h, w = crop.shape\n",
    "    s = max(h, w) + 2*pad\n",
    "    pad_t = (s - h) // 2\n",
    "    pad_b = s - h - pad_t\n",
    "    pad_l = (s - w) // 2\n",
    "    pad_r = s - w - pad_l\n",
    "    sq = np.pad(crop, ((pad_t, pad_b), (pad_l, pad_r)), constant_values=1.0)\n",
    "    # resize to out x out and invert so digit is bright\n",
    "    img28 = resize(sq, (out, out), anti_aliasing=True)\n",
    "    img28 = 1.0 - img28  # digit -> high, background -> low\n",
    "    img28 = np.clip(img28, 0, 1)\n",
    "    return img28\n",
    "\n",
    "digits = [crop_norm(gray, b) for b in boxes]\n",
    "\n",
    "# show a grid\n",
    "n = len(digits)\n",
    "assert n > 0, 'No components found to crop.'\n",
    "cols = min(8, n)\n",
    "rows = int(np.ceil(n / cols))\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(1.5*cols, 1.5*rows))\n",
    "axes = np.array(axes).reshape(rows, cols)\n",
    "k = 0\n",
    "for r in range(rows):\n",
    "    for c in range(cols):\n",
    "        ax = axes[r, c]\n",
    "        ax.axis('off')\n",
    "        if k < n:\n",
    "            ax.imshow(digits[k], cmap='gray', vmin=0, vmax=1)\n",
    "            k += 1\n",
    "plt.suptitle(f'Extracted digits: {n}', y=0.98)\n",
    "plt.tight_layout()"
   ],
   "id": "a3b1a612ad132c18",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x150 with 8 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Classify the extracted 28×28 crops with the MNIST CNN; prints predicted sequence. If TensorFlow isn’t installed on this Python (e.g., 3.13), it skips classification.",
   "id": "3135963a7a3f0678"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T08:58:01.713613Z",
     "start_time": "2025-10-27T08:58:01.704938Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ensure HW_1/src is on sys.path so `from model import ...` works\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def add_src_to_path():\n",
    "    bases = [Path.cwd(), *Path.cwd().parents]\n",
    "    for base in bases:\n",
    "        for rel in ('src', 'HW_1/src'):\n",
    "            cand = base / rel\n",
    "            if (cand / 'model.py').exists():\n",
    "                if str(cand) not in sys.path:\n",
    "                    sys.path.insert(0, str(cand))\n",
    "                print('Using src path:', cand)\n",
    "                return True\n",
    "    print('model.py not found. Check that HW_1/src/model.py exists.')\n",
    "    return False\n",
    "\n",
    "ok = add_src_to_path()\n",
    "if ok:\n",
    "    try:\n",
    "        from model import load_or_train_default, predict_digits\n",
    "        print('Import OK: load_or_train_default, predict_digits')\n",
    "    except Exception as e:\n",
    "        print('Import still failed:', e)\n",
    "\n",
    "# Now re-run the previous classification cell."
   ],
   "id": "ad9849cc1b74da92",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using src path: /Users/evomr/Desktop/TSM_CompVis/HW_1/src\n",
      "Import OK: load_or_train_default, predict_digits\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T08:58:27.268586Z",
     "start_time": "2025-10-27T08:58:16.051851Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Rebuild boxes and 28x28 digit crops\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import gaussian, threshold_otsu\n",
    "from skimage.transform import resize\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "# load image if needed\n",
    "if 'img' not in globals():\n",
    "    IMAGES_DIR = globals().get('IMAGES_DIR', Path.cwd() / 'images1')\n",
    "    img = io.imread(sorted(IMAGES_DIR.glob('*.jpg'))[0])\n",
    "\n",
    "gray = rgb2gray(img)\n",
    "mask = gaussian(gray, 1.0) < threshold_otsu(gaussian(gray, 1.0))\n",
    "\n",
    "labels, _ = ndi.label(mask)\n",
    "slices = ndi.find_objects(labels)\n",
    "areas = np.bincount(labels.ravel())\n",
    "min_size = 150\n",
    "\n",
    "boxes = []\n",
    "for i, slc in enumerate(slices, start=1):\n",
    "    if slc is None or areas[i] < min_size:\n",
    "        continue\n",
    "    r0, r1 = slc[0].start, slc[0].stop\n",
    "    c0, c1 = slc[1].start, slc[1].stop\n",
    "    boxes.append((r0, c0, r1, c1))\n",
    "\n",
    "# simple reading order\n",
    "boxes.sort(key=lambda b: (b[0], b[1]))\n",
    "\n",
    "def to28(g, b, out=28, pad=2):\n",
    "    r0, c0, r1, c1 = b\n",
    "    crop = g[r0:r1, c0:c1]\n",
    "    h, w = crop.shape\n",
    "    s = max(h, w) + 2*pad\n",
    "    pt, pb = (s - h)//2, s - h - (s - h)//2\n",
    "    pl, pr = (s - w)//2, s - w - (s - w)//2\n",
    "    sq = np.pad(crop, ((pt, pb), (pl, pr)), constant_values=1.0)  # white bg\n",
    "    img28 = resize(sq, (out, out), anti_aliasing=True)\n",
    "    return np.clip(1.0 - img28, 0, 1)  # invert: digit bright\n",
    "\n",
    "digits = [to28(gray, b) for b in boxes]\n",
    "print(f'Rebuilt digits: {len(digits)}')"
   ],
   "id": "25ba617ffad20381",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rebuilt digits: 8\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Classify the 28×28 crops with the MNIST CNN; prints the predicted sequence",
   "id": "e484b7e5392b9047"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-27T08:59:24.583445Z",
     "start_time": "2025-10-27T08:59:03.652245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# python\n",
    "# Extract 28x28 digits from the first JPG in `images1` and optionally classify\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from skimage import io, color, filters, transform\n",
    "from scipy import ndimage as ndi\n",
    "import importlib.util, sys\n",
    "\n",
    "def extract_digits(images_dir='images1', min_size=150, out=28, pad=2):\n",
    "    p = Path(images_dir)\n",
    "    img_file = next(p.glob('*.jpg'), None)\n",
    "    assert img_file is not None, f'No .jpg in {p}'\n",
    "    img = io.imread(img_file)\n",
    "    gray = color.rgb2gray(img)\n",
    "    blur = filters.gaussian(gray, sigma=1.0)\n",
    "    mask = blur < filters.threshold_otsu(blur)\n",
    "    labels, _ = ndi.label(mask)\n",
    "    slices = ndi.find_objects(labels)\n",
    "    areas = np.bincount(labels.ravel())\n",
    "    boxes = []\n",
    "    for i, slc in enumerate(slices, start=1):\n",
    "        if slc is None or areas[i] < min_size:\n",
    "            continue\n",
    "        r0, r1 = slc[0].start, slc[0].stop\n",
    "        c0, c1 = slc[1].start, slc[1].stop\n",
    "        boxes.append((r0, c0, r1, c1))\n",
    "    if not boxes:\n",
    "        return []\n",
    "    # reading order\n",
    "    med_h = max(1, int(np.median([b[2]-b[0] for b in boxes])))\n",
    "    row_h = max(1, int(0.6 * med_h))\n",
    "    boxes = sorted(boxes, key=lambda b: (b[0] // row_h, b[1]))\n",
    "    def to28(g, b):\n",
    "        r0, c0, r1, c1 = b\n",
    "        crop = g[r0:r1, c0:c1]\n",
    "        # trim empty margins\n",
    "        thr = np.percentile(crop, 80)\n",
    "        mask = crop < thr\n",
    "        if mask.any():\n",
    "            rr = np.where(mask.any(axis=1))[0]\n",
    "            cc = np.where(mask.any(axis=0))[0]\n",
    "            crop = crop[rr.min():rr.max()+1, cc.min():cc.max()+1]\n",
    "        h, w = crop.shape\n",
    "        s = max(h, w) + 2*pad\n",
    "        pt = (s - h)//2; pl = (s - w)//2\n",
    "        sq = np.pad(crop, ((pt, s - h - pt), (pl, s - w - pl)), constant_values=1.0)\n",
    "        img28 = transform.resize(sq, (out, out), anti_aliasing=True)\n",
    "        return np.clip(1.0 - img28, 0, 1)\n",
    "    digits = [to28(gray, b) for b in boxes]\n",
    "    return digits\n",
    "\n",
    "# Usage:\n",
    "digits = extract_digits('images1')\n",
    "assert len(digits) > 0, 'No digit crops found; check images and dependencies.'\n",
    "print('Extracted digits:', len(digits))\n",
    "\n",
    "# Optional: import local model implementation at `HW_1/src/model.py` and classify\n",
    "model_py = Path.cwd() / 'HW_1' / 'src' / 'model.py'\n",
    "if model_py.exists():\n",
    "    spec = importlib.util.spec_from_file_location('cv_hw_model', str(model_py))\n",
    "    cv_hw_model = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(cv_hw_model)\n",
    "    try:\n",
    "        model = cv_hw_model.load_or_train_default(str(Path.cwd() / 'model.h5'))\n",
    "        patches = (np.array(digits) * 255).astype(np.uint8)\n",
    "        preds = cv_hw_model.predict_digits(model, patches)\n",
    "        print('Predicted:', ''.join(map(str, preds.tolist())))\n",
    "    except Exception as e:\n",
    "        print('Classification skipped or failed:', type(e).__name__, e)\n",
    "else:\n",
    "    print('Local model.py not found at `HW_1/src/model.py`; skipping classification.')"
   ],
   "id": "54fef18bf5297ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted digits: 80\n",
      "Local model.py not found at `HW_1/src/model.py`; skipping classification.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "359e3459d98d7cab"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
