{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Initializes notebook: inline plots, adds src/ to Python path, sets IMAGES_DIR to images1/, and prints the path.",
   "id": "7e77f6bfe2bbf30a"
  },
  {
   "cell_type": "code",
   "id": "5eef0d73304fe920",
   "metadata": {},
   "source": [
    "# Initial setup: paths and imports\n",
    "%matplotlib inline\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "SRC_DIR = ROOT / 'src'\n",
    "if SRC_DIR.exists() and str(SRC_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC_DIR))  # allow `import ...` from local src/\n",
    "\n",
    "IMAGES_DIR = ROOT / 'images1'\n",
    "print('Ready. Images path:', IMAGES_DIR)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Lists JPGs in IMAGES_DIR and displays the first one (RGB) with title and shape.",
   "id": "dac764f682bcb902"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Preview a sample image (robust if setup cell wasn't run)\n",
    "from pathlib import Path\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "IMAGES_DIR = globals().get('IMAGES_DIR', Path.cwd() / 'images1')\n",
    "\n",
    "image_files = sorted(IMAGES_DIR.glob('*.jpg'))\n",
    "assert image_files, f'No .jpg images found in {IMAGES_DIR}'\n",
    "\n",
    "img_path = image_files[0]\n",
    "img = io.imread(img_path)  # RGB\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.title(img_path.name)\n",
    "plt.axis('off')\n",
    "print('Image shape:', img.shape)"
   ],
   "id": "bf5095d1b648e0e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Binarize the sample image: convert to grayscale, lightly blur, apply Otsu threshold, and show original vs binary.",
   "id": "7ea87e434c4b44a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Binarize image: grayscale -> blur -> Otsu threshold\n",
    "from pathlib import Path\n",
    "from skimage import io\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import gaussian, threshold_otsu\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# reuse loaded image if present; otherwise load first jpg\n",
    "if 'img' not in globals():\n",
    "    IMAGES_DIR = globals().get('IMAGES_DIR', Path.cwd() / 'images1')\n",
    "    img_path = sorted(IMAGES_DIR.glob('*.jpg'))[0]\n",
    "    img = io.imread(img_path)\n",
    "\n",
    "gray = rgb2gray(img)              # 0..1 float\n",
    "blur = gaussian(gray, sigma=1.0)  # light denoise\n",
    "t = threshold_otsu(blur)\n",
    "bw = blur < t                     # ink is dark -> True\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "axes[0].imshow(img);  axes[0].set_title('Original');  axes[0].axis('off')\n",
    "axes[1].imshow(bw, cmap='gray'); axes[1].set_title(f'Binarized (t={t:.3f})'); axes[1].axis('off')\n",
    "print('gray shape:', gray.shape, 'threshold:', t)"
   ],
   "id": "f11fdf16f1e866d8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Clean the binary mask by removing small components (noise); visualize before vs. after.",
   "id": "8c360ee0ff2b6d64"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Clean binary mask: remove tiny components (noise)\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.morphology import remove_small_objects\n",
    "\n",
    "# fallbacks if earlier cells weren't run\n",
    "if 'img' not in globals():\n",
    "    from pathlib import Path\n",
    "    from skimage import io\n",
    "    IMAGES_DIR = globals().get('IMAGES_DIR', Path.cwd() / 'images1')\n",
    "    img = io.imread(sorted(IMAGES_DIR.glob('*.jpg'))[0])\n",
    "if 'bw' not in globals():\n",
    "    from skimage.color import rgb2gray\n",
    "    from skimage.filters import gaussian, threshold_otsu\n",
    "    gray = rgb2gray(img)\n",
    "    t = threshold_otsu(gaussian(gray, 1.0))\n",
    "    bw = gray < t\n",
    "\n",
    "clean = remove_small_objects(bw, min_size=150)  # adjust if needed\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "axes[0].imshow(bw, cmap='gray');    axes[0].set_title('Binary');  axes[0].axis('off')\n",
    "axes[1].imshow(clean, cmap='gray'); axes[1].set_title('Cleaned'); axes[1].axis('off')"
   ],
   "id": "9d698a3470723a3a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Label connected components on the cleaned mask and draw bounding boxes over the original image.",
   "id": "7b05423d352185eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Fix: compute boxes using .start/.stop from find_objects slices\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from scipy import ndimage as ndi\n",
    "from skimage import io\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import gaussian, threshold_otsu\n",
    "from pathlib import Path\n",
    "\n",
    "# fallbacks if earlier cells weren't run\n",
    "if 'img' not in globals():\n",
    "    IMAGES_DIR = globals().get('IMAGES_DIR', Path.cwd() / 'images1')\n",
    "    img = io.imread(sorted(IMAGES_DIR.glob('*.jpg'))[0])\n",
    "if 'clean' not in globals():\n",
    "    gray = rgb2gray(img)\n",
    "    blur = gaussian(gray, 1.0)\n",
    "    clean = blur < threshold_otsu(blur)\n",
    "\n",
    "min_size = 150\n",
    "\n",
    "labels, num = ndi.label(clean)\n",
    "slices = ndi.find_objects(labels)\n",
    "areas = np.bincount(labels.ravel())  # area per label (index 0 is background)\n",
    "\n",
    "boxes = []\n",
    "for i, slc in enumerate(slices, start=1):  # labels 1..num\n",
    "    if slc is None:\n",
    "        continue\n",
    "    r0, r1 = slc[0].start, slc[0].stop\n",
    "    c0, c1 = slc[1].start, slc[1].stop\n",
    "    if areas[i] < min_size:\n",
    "        continue\n",
    "    boxes.append((r0, c0, r1, c1))\n",
    "\n",
    "boxes.sort(key=lambda b: b[1])  # left-to-right\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.imshow(img)\n",
    "for r0, c0, r1, c1 in boxes:\n",
    "    ax.add_patch(Rectangle((c0, r0), c1 - c0, r1 - r0,\n",
    "                           fill=False, edgecolor='lime', linewidth=2))\n",
    "ax.set_title(f'Components (SciPy): {len(boxes)}')\n",
    "ax.axis('off')\n",
    "print('Detected components:', len(boxes))"
   ],
   "id": "da0ab70124203172",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Extract component crops, pad to square, resize to 28×28, and display them in reading order.",
   "id": "f7c4487925d2bc33"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Extract crops from boxes, pad to square, resize to 28x28, show grid\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import resize\n",
    "from pathlib import Path\n",
    "\n",
    "# fallbacks\n",
    "if 'img' not in globals():\n",
    "    from skimage import io\n",
    "    IMAGES_DIR = globals().get('IMAGES_DIR', Path.cwd() / 'images1')\n",
    "    img = io.imread(sorted(IMAGES_DIR.glob('*.jpg'))[0])\n",
    "if 'gray' not in globals():\n",
    "    gray = rgb2gray(img)\n",
    "\n",
    "# if boxes missing, compute from clean mask quickly\n",
    "if 'boxes' not in globals():\n",
    "    from scipy import ndimage as ndi\n",
    "    from skimage.filters import gaussian, threshold_otsu\n",
    "    blur = gaussian(gray, 1.0)\n",
    "    clean = blur < threshold_otsu(blur)\n",
    "    labels, _ = ndi.label(clean)\n",
    "    slices = ndi.find_objects(labels)\n",
    "    areas = np.bincount(labels.ravel())\n",
    "    min_size = 150\n",
    "    boxes = []\n",
    "    for i, slc in enumerate(slices, start=1):\n",
    "        if slc is None or areas[i] < min_size:\n",
    "            continue\n",
    "        r0, r1 = slc[0].start, slc[0].stop\n",
    "        c0, c1 = slc[1].start, slc[1].stop\n",
    "        boxes.append((r0, c0, r1, c1))\n",
    "\n",
    "# sort reading order: top-to-bottom then left-to-right\n",
    "if boxes:\n",
    "    med_h = np.median([b[2]-b[0] for b in boxes]) or 1\n",
    "    row_h = max(1, int(0.6 * med_h))\n",
    "    boxes = sorted(boxes, key=lambda b: (b[0] // row_h, b[1]))\n",
    "\n",
    "def crop_norm(g, b, out=28, pad=2):\n",
    "    r0, c0, r1, c1 = b\n",
    "    crop = g[r0:r1, c0:c1]\n",
    "    # trim empty margins using a simple threshold\n",
    "    thr = np.percentile(crop, 80)  # paper is bright\n",
    "    mask = crop < thr\n",
    "    if mask.any():\n",
    "        rr = np.where(mask.any(axis=1))[0]\n",
    "        cc = np.where(mask.any(axis=0))[0]\n",
    "        crop = crop[rr.min():rr.max()+1, cc.min():cc.max()+1]\n",
    "    # pad to square (white background ~1.0)\n",
    "    h, w = crop.shape\n",
    "    s = max(h, w) + 2*pad\n",
    "    pad_t = (s - h) // 2\n",
    "    pad_b = s - h - pad_t\n",
    "    pad_l = (s - w) // 2\n",
    "    pad_r = s - w - pad_l\n",
    "    sq = np.pad(crop, ((pad_t, pad_b), (pad_l, pad_r)), constant_values=1.0)\n",
    "    # resize to out x out and invert so digit is bright\n",
    "    img28 = resize(sq, (out, out), anti_aliasing=True)\n",
    "    img28 = 1.0 - img28  # digit -> high, background -> low\n",
    "    img28 = np.clip(img28, 0, 1)\n",
    "    return img28\n",
    "\n",
    "digits = [crop_norm(gray, b) for b in boxes]\n",
    "\n",
    "# show a grid\n",
    "n = len(digits)\n",
    "assert n > 0, 'No components found to crop.'\n",
    "cols = min(8, n)\n",
    "rows = int(np.ceil(n / cols))\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(1.5*cols, 1.5*rows))\n",
    "axes = np.array(axes).reshape(rows, cols)\n",
    "k = 0\n",
    "for r in range(rows):\n",
    "    for c in range(cols):\n",
    "        ax = axes[r, c]\n",
    "        ax.axis('off')\n",
    "        if k < n:\n",
    "            ax.imshow(digits[k], cmap='gray', vmin=0, vmax=1)\n",
    "            k += 1\n",
    "plt.suptitle(f'Extracted digits: {n}', y=0.98)\n",
    "plt.tight_layout()"
   ],
   "id": "a3b1a612ad132c18",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Classify the extracted 28×28 crops with the MNIST CNN; prints predicted sequence. If TensorFlow isn’t installed on this Python (e.g., 3.13), it skips classification.",
   "id": "3135963a7a3f0678"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Ensure HW_1/src is on sys.path so `from model import ...` works\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def add_src_to_path():\n",
    "    bases = [Path.cwd(), *Path.cwd().parents]\n",
    "    for base in bases:\n",
    "        for rel in ('src', 'HW_1/src'):\n",
    "            cand = base / rel\n",
    "            if (cand / 'model.py').exists():\n",
    "                if str(cand) not in sys.path:\n",
    "                    sys.path.insert(0, str(cand))\n",
    "                print('Using src path:', cand)\n",
    "                return True\n",
    "    print('model.py not found. Check that HW_1/src/model.py exists.')\n",
    "    return False\n",
    "\n",
    "ok = add_src_to_path()\n",
    "if ok:\n",
    "    try:\n",
    "        from model import load_or_train_default, predict_digits\n",
    "        print('Import OK: load_or_train_default, predict_digits')\n",
    "    except Exception as e:\n",
    "        print('Import still failed:', e)\n",
    "\n",
    "# Now re-run the previous classification cell."
   ],
   "id": "ad9849cc1b74da92",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Rebuild boxes and 28x28 digit crops\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import gaussian, threshold_otsu\n",
    "from skimage.transform import resize\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "# load image if needed\n",
    "if 'img' not in globals():\n",
    "    IMAGES_DIR = globals().get('IMAGES_DIR', Path.cwd() / 'images1')\n",
    "    img = io.imread(sorted(IMAGES_DIR.glob('*.jpg'))[0])\n",
    "\n",
    "gray = rgb2gray(img)\n",
    "mask = gaussian(gray, 1.0) < threshold_otsu(gaussian(gray, 1.0))\n",
    "\n",
    "labels, _ = ndi.label(mask)\n",
    "slices = ndi.find_objects(labels)\n",
    "areas = np.bincount(labels.ravel())\n",
    "min_size = 150\n",
    "\n",
    "boxes = []\n",
    "for i, slc in enumerate(slices, start=1):\n",
    "    if slc is None or areas[i] < min_size:\n",
    "        continue\n",
    "    r0, r1 = slc[0].start, slc[0].stop\n",
    "    c0, c1 = slc[1].start, slc[1].stop\n",
    "    boxes.append((r0, c0, r1, c1))\n",
    "\n",
    "# simple reading order\n",
    "boxes.sort(key=lambda b: (b[0], b[1]))\n",
    "\n",
    "def to28(g, b, out=28, pad=2):\n",
    "    r0, c0, r1, c1 = b\n",
    "    crop = g[r0:r1, c0:c1]\n",
    "    h, w = crop.shape\n",
    "    s = max(h, w) + 2*pad\n",
    "    pt, pb = (s - h)//2, s - h - (s - h)//2\n",
    "    pl, pr = (s - w)//2, s - w - (s - w)//2\n",
    "    sq = np.pad(crop, ((pt, pb), (pl, pr)), constant_values=1.0)  # white bg\n",
    "    img28 = resize(sq, (out, out), anti_aliasing=True)\n",
    "    return np.clip(1.0 - img28, 0, 1)  # invert: digit bright\n",
    "\n",
    "digits = [to28(gray, b) for b in boxes]\n",
    "print(f'Rebuilt digits: {len(digits)}')"
   ],
   "id": "25ba617ffad20381",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Classify the 28×28 crops with the MNIST CNN; prints the predicted sequence",
   "id": "e484b7e5392b9047"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# python\n",
    "# Extract 28x28 digits from the first JPG in `images1` and optionally classify\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from skimage import io, color, filters, transform\n",
    "from scipy import ndimage as ndi\n",
    "import importlib.util, sys\n",
    "\n",
    "def extract_digits(images_dir='images1', min_size=150, out=28, pad=2):\n",
    "    p = Path(images_dir)\n",
    "    img_file = next(p.glob('*.jpg'), None)\n",
    "    assert img_file is not None, f'No .jpg in {p}'\n",
    "    img = io.imread(img_file)\n",
    "    gray = color.rgb2gray(img)\n",
    "    blur = filters.gaussian(gray, sigma=1.0)\n",
    "    mask = blur < filters.threshold_otsu(blur)\n",
    "    labels, _ = ndi.label(mask)\n",
    "    slices = ndi.find_objects(labels)\n",
    "    areas = np.bincount(labels.ravel())\n",
    "    boxes = []\n",
    "    for i, slc in enumerate(slices, start=1):\n",
    "        if slc is None or areas[i] < min_size:\n",
    "            continue\n",
    "        r0, r1 = slc[0].start, slc[0].stop\n",
    "        c0, c1 = slc[1].start, slc[1].stop\n",
    "        boxes.append((r0, c0, r1, c1))\n",
    "    if not boxes:\n",
    "        return []\n",
    "    # reading order\n",
    "    med_h = max(1, int(np.median([b[2]-b[0] for b in boxes])))\n",
    "    row_h = max(1, int(0.6 * med_h))\n",
    "    boxes = sorted(boxes, key=lambda b: (b[0] // row_h, b[1]))\n",
    "    def to28(g, b):\n",
    "        r0, c0, r1, c1 = b\n",
    "        crop = g[r0:r1, c0:c1]\n",
    "        # trim empty margins\n",
    "        thr = np.percentile(crop, 80)\n",
    "        mask = crop < thr\n",
    "        if mask.any():\n",
    "            rr = np.where(mask.any(axis=1))[0]\n",
    "            cc = np.where(mask.any(axis=0))[0]\n",
    "            crop = crop[rr.min():rr.max()+1, cc.min():cc.max()+1]\n",
    "        h, w = crop.shape\n",
    "        s = max(h, w) + 2*pad\n",
    "        pt = (s - h)//2; pl = (s - w)//2\n",
    "        sq = np.pad(crop, ((pt, s - h - pt), (pl, s - w - pl)), constant_values=1.0)\n",
    "        img28 = transform.resize(sq, (out, out), anti_aliasing=True)\n",
    "        return np.clip(1.0 - img28, 0, 1)\n",
    "    digits = [to28(gray, b) for b in boxes]\n",
    "    return digits\n",
    "\n",
    "# Usage:\n",
    "digits = extract_digits('images1')\n",
    "assert len(digits) > 0, 'No digit crops found; check images and dependencies.'\n",
    "print('Extracted digits:', len(digits))\n",
    "\n",
    "# Optional: import local model implementation at `HW_1/src/model.py` and classify\n",
    "model_py = Path.cwd() / 'HW_1' / 'src' / 'model.py'\n",
    "if model_py.exists():\n",
    "    spec = importlib.util.spec_from_file_location('cv_hw_model', str(model_py))\n",
    "    cv_hw_model = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(cv_hw_model)\n",
    "    try:\n",
    "        model = cv_hw_model.load_or_train_default(str(Path.cwd() / 'model.h5'))\n",
    "        patches = (np.array(digits) * 255).astype(np.uint8)\n",
    "        preds = cv_hw_model.predict_digits(model, patches)\n",
    "        print('Predicted:', ''.join(map(str, preds.tolist())))\n",
    "    except Exception as e:\n",
    "        print('Classification skipped or failed:', type(e).__name__, e)\n",
    "else:\n",
    "    print('Local model.py not found at `HW_1/src/model.py`; skipping classification.')"
   ],
   "id": "54fef18bf5297ea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Detects paper corners and warps the sheet to A4; it shows results and keeps warped images for later",
   "id": "84d4a8a2f3997bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Detect paper corners and warp to A4; keeps warped_bgr/warped_gray for later steps\n",
    "from pathlib import Path\n",
    "import sys, cv2, numpy as np, matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure local src/ is importable\n",
    "SRC_DIR = Path.cwd() / 'src'\n",
    "if SRC_DIR.exists() and str(SRC_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC_DIR))\n",
    "\n",
    "from paper_detect import detect_paper_corners, warp_to_a4  # uses OpenCV\n",
    "\n",
    "# Pick a sample image (first .jpg in images1)\n",
    "IMAGES_DIR = Path.cwd() / 'images1'\n",
    "image_files = sorted(IMAGES_DIR.glob('*.jpg'))\n",
    "assert image_files, f'No .jpg images found in {IMAGES_DIR}'\n",
    "img_path = image_files[0]\n",
    "\n",
    "bgr = cv2.imread(str(img_path))\n",
    "assert bgr is not None, f'Failed to read {img_path}'\n",
    "\n",
    "corners = detect_paper_corners(bgr)  # (4,2) [tl,tr,br,bl] or None\n",
    "if corners is None:\n",
    "    print('Paper not found in', img_path.name)\n",
    "else:\n",
    "    vis = bgr.copy()\n",
    "    for (x, y) in corners.astype(int):\n",
    "        cv2.circle(vis, (x, y), 6, (0, 0, 255), -1)  # draw corner\n",
    "\n",
    "    warped = warp_to_a4(bgr, corners)  # perspective warp to A4 ratio\n",
    "\n",
    "    # Show original + corners vs warped\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axes[0].imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB)); axes[0].set_title(f'{img_path.name} + corners'); axes[0].axis('off')\n",
    "    axes[1].imshow(cv2.cvtColor(warped, cv2.COLOR_BGR2RGB)); axes[1].set_title('Warped (A4)'); axes[1].axis('off')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Keep for later cells\n",
    "    warped_bgr = warped\n",
    "    warped_gray = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)\n",
    "    print('Corners (tl,tr,br,bl):\\n', corners.astype(int))"
   ],
   "id": "f521a181fa6f611f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Binarize the warped sheet, extract components, draw boxes, and prepare 28×28 crops. Insert this as one code cell into",
   "id": "48f307e7af7a5733"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Binarize warped sheet, extract components, draw boxes, and prepare 28x28 digit crops\n",
    "from pathlib import Path\n",
    "import sys, numpy as np, cv2, matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure local src/ is importable\n",
    "SRC_DIR = Path.cwd() / 'src'\n",
    "if SRC_DIR.exists() and str(SRC_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC_DIR))\n",
    "\n",
    "from paper_detect import detect_paper_corners, warp_to_a4\n",
    "from segments import binarize, extract_components, crop_and_resize\n",
    "\n",
    "# Ensure we have a warped image from the previous cell; fallback if missing\n",
    "if 'warped_bgr' not in globals():\n",
    "    IMAGES_DIR = Path.cwd() / 'images1'\n",
    "    img_path = next(iter(sorted(IMAGES_DIR.glob('*.jpg'))), None)\n",
    "    assert img_path is not None, f'No .jpg images in {IMAGES_DIR}'\n",
    "    bgr0 = cv2.imread(str(img_path)); assert bgr0 is not None\n",
    "    c = detect_paper_corners(bgr0)\n",
    "    warped_bgr = warp_to_a4(bgr0, c) if c is not None else bgr0\n",
    "\n",
    "# 1) Binarize (robust to uneven illumination)\n",
    "bin_img = binarize(warped_bgr)\n",
    "\n",
    "# 2) Extract connected components (boxes: x,y,w,h), sorted top->bottom then left->right\n",
    "boxes = extract_components(bin_img)\n",
    "\n",
    "# 3) Visualize boxes on warped image and the binary mask\n",
    "vis = warped_bgr.copy()\n",
    "for (x, y, w, h) in boxes:\n",
    "    cv2.rectangle(vis, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].imshow(cv2.cvtColor(vis, cv2.COLOR_BGR2RGB)); axes[0].set_title(f'Boxes: {len(boxes)}'); axes[0].axis('off')\n",
    "axes[1].imshow(bin_img, cmap='gray'); axes[1].set_title('Binary'); axes[1].axis('off')\n",
    "plt.tight_layout()\n",
    "\n",
    "# 4) Crop and resize to 28x28 (MNIST-style: digit bright on dark). Keep for later classification.\n",
    "if boxes:\n",
    "    patches28 = np.stack([crop_and_resize(warped_bgr, b, 28) for b in boxes], axis=0).astype(np.uint8)\n",
    "    # Show a small grid\n",
    "    n = len(patches28); cols = min(8, n); rows = int(np.ceil(n / cols))\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(1.4*cols, 1.4*rows))\n",
    "    axes = np.atleast_2d(axes)\n",
    "    k = 0\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            ax = axes[r, c] if rows > 1 or cols > 1 else axes[0, 0]\n",
    "            ax.axis('off')\n",
    "            if k < n:\n",
    "                ax.imshow(patches28[k], cmap='gray', vmin=0, vmax=255); k += 1\n",
    "    plt.suptitle(f'28×28 digit crops: {n}', y=0.98); plt.tight_layout()\n",
    "else:\n",
    "    patches28 = np.empty((0, 28, 28), dtype=np.uint8)\n",
    "\n",
    "print(f'Components found: {len(boxes)}; patches28 shape: {patches28.shape}')"
   ],
   "id": "613fc53d93697e98",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Classify the 28×28 crops from the previous step and print the predicted digit sequence.",
   "id": "f7f37dadec49ec72"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Classify 28x28 digit crops (patches28) with the MNIST CNN and print the sequence\n",
    "from pathlib import Path\n",
    "import sys, numpy as np, matplotlib.pyplot as plt\n",
    "\n",
    "# Ensure local src is importable (tries ./src and ./HW_1/src)\n",
    "for base in (Path.cwd(), Path.cwd() / 'HW_1'):\n",
    "    cand = base / 'src'\n",
    "    if (cand / 'model.py').exists() and str(cand) not in sys.path:\n",
    "        sys.path.insert(0, str(cand))\n",
    "\n",
    "try:\n",
    "    from model import load_or_train_default, predict_digits\n",
    "except Exception as e:\n",
    "    print('Classification unavailable: cannot import model.py:', e)\n",
    "    preds = np.array([], dtype=int)\n",
    "else:\n",
    "    # Build patches28 if missing (uses warped_bgr from previous cell)\n",
    "    if 'patches28' not in globals() or patches28.size == 0:\n",
    "        try:\n",
    "            from segments import binarize, extract_components, crop_and_resize\n",
    "            from paper_detect import detect_paper_corners, warp_to_a4\n",
    "            import cv2\n",
    "            # Try to create from warped_bgr; otherwise from first image in images1/\n",
    "            if 'warped_bgr' not in globals():\n",
    "                IMAGES_DIR = Path.cwd() / 'images1'\n",
    "                img_path = next(iter(sorted(IMAGES_DIR.glob('*.jpg'))), None)\n",
    "                assert img_path is not None, f'No .jpg images in {IMAGES_DIR}'\n",
    "                bgr0 = cv2.imread(str(img_path)); assert bgr0 is not None\n",
    "                c = detect_paper_corners(bgr0)\n",
    "                warped_bgr = warp_to_a4(bgr0, c) if c is not None else bgr0\n",
    "            bin_img = binarize(warped_bgr)\n",
    "            boxes = extract_components(bin_img)\n",
    "            patches28 = np.stack([crop_and_resize(warped_bgr, b, 28) for b in boxes], axis=0).astype(np.uint8) if boxes else np.empty((0,28,28), np.uint8)\n",
    "        except Exception as e:\n",
    "            print('Could not prepare patches28 automatically:', e)\n",
    "            patches28 = np.empty((0,28,28), np.uint8)\n",
    "\n",
    "    if patches28.size == 0:\n",
    "        print('No digit crops available (patches28 is empty).')\n",
    "        preds = np.array([], dtype=int)\n",
    "    else:\n",
    "        try:\n",
    "            model_path = Path.cwd() / 'HW_1' / 'model.h5'\n",
    "            model = load_or_train_default(str(model_path))  # trains briefly if file missing\n",
    "            preds = predict_digits(model, patches28)\n",
    "        except Exception as e:\n",
    "            print('Classification skipped or failed:', e)\n",
    "            preds = np.array([], dtype=int)\n",
    "\n",
    "# Report results and quick visualization\n",
    "if preds.size:\n",
    "    seq = ''.join(map(str, preds.tolist()))\n",
    "    print('Predicted sequence:', seq)\n",
    "    # Show a small grid with predicted labels\n",
    "    n = len(patches28); cols = min(8, n); rows = int(np.ceil(n / cols))\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(1.4*cols, 1.6*rows))\n",
    "    axes = np.atleast_2d(axes)\n",
    "    k = 0\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            ax = axes[r, c] if rows > 1 or cols > 1 else axes[0, 0]\n",
    "            ax.axis('off')\n",
    "            if k < n:\n",
    "                ax.imshow(patches28[k], cmap='gray', vmin=0, vmax=255)\n",
    "                ax.set_title(str(int(preds[k])), fontsize=10)\n",
    "                k += 1\n",
    "    plt.tight_layout()\n",
    "else:\n",
    "    print('No predictions to display.')"
   ],
   "id": "93fc725d5c1b4370",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Process all images in a directory and print “filename: digits” per file.",
   "id": "4868d4b18fb06a65"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Reload src modules and re-run processing for all images (uses fixed corner refinement)\n",
    "from pathlib import Path\n",
    "import sys, importlib\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))  # allow `import src.*`\n",
    "\n",
    "import src.paper_detect as paper_detect\n",
    "import src.segments as segments\n",
    "import src.model as model_mod\n",
    "import src.pipeline as pipeline\n",
    "\n",
    "# Reload to pick up latest edits on disk\n",
    "for m in (paper_detect, segments, model_mod, pipeline):\n",
    "    importlib.reload(m)\n",
    "\n",
    "images_dir = ROOT / 'images1'  # change to 'images2' to test the other set\n",
    "assert images_dir.exists(), f'Missing images directory: {images_dir}'\n",
    "\n",
    "# Collect files\n",
    "files = []\n",
    "for ext in ('*.jpg','*.jpeg','*.png','*.JPG','*.PNG'):\n",
    "    files += sorted(images_dir.glob(ext))\n",
    "assert files, f'No images found in {images_dir}'\n",
    "\n",
    "# Load/train model (skips if TF unavailable)\n",
    "model_path = ROOT / 'HW_1' / 'model.h5'\n",
    "try:\n",
    "    model = model_mod.load_or_train_default(str(model_path))\n",
    "except Exception:\n",
    "    print('TensorFlow/Keras unavailable; proceeding without classification.')\n",
    "    model = None\n",
    "\n",
    "# Run pipeline per file with safety guard\n",
    "for p in files:\n",
    "    try:\n",
    "        print(pipeline.process_image(p, model, model_path))\n",
    "    except Exception as e:\n",
    "        print(f'{p.name}: [error: {type(e).__name__}]')"
   ],
   "id": "b566866462d42724",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": " Prints “filename: digits”, and saves overlays/grids and a results file to HW_1/results.",
   "id": "8ba6f53a633a09f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Process all images, print \"filename: digits\", and save overlays/grids + results.txt to HW_1/results\n",
    "from pathlib import Path\n",
    "import sys, os, cv2, numpy as np, matplotlib.pyplot as plt\n",
    "\n",
    "# Make src importable (tries ./src and ./HW_1/src)\n",
    "ROOT = Path.cwd()\n",
    "for cand in (ROOT / 'src', ROOT / 'HW_1' / 'src'):\n",
    "    if (cand / '__init__.py').exists() and str(cand) not in sys.path:\n",
    "        sys.path.insert(0, str(cand))\n",
    "\n",
    "# Imports from src\n",
    "try:\n",
    "    from paper_detect import detect_paper_corners, warp_to_a4\n",
    "    from segments import binarize, extract_components, crop_and_resize\n",
    "    from model import load_or_train_default, predict_digits\n",
    "except Exception as e:\n",
    "    raise RuntimeError('Failed to import from src/. Ensure HW_1/src is present.') from e\n",
    "\n",
    "# Config\n",
    "images_dir = ROOT / 'images1'  # change to ROOT / 'images2' to run the other set\n",
    "out_dir = ROOT / 'HW_1' / 'results'\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Collect input files\n",
    "files = []\n",
    "for ext in ('*.jpg','*.jpeg','*.png','*.JPG','*.PNG'):\n",
    "    files += sorted(images_dir.glob(ext))\n",
    "assert files, f'No images found in {images_dir}'\n",
    "\n",
    "# Load model (skips classification if TF unavailable)\n",
    "try:\n",
    "    model_path = ROOT / 'HW_1' / 'model.h5'\n",
    "    model = load_or_train_default(str(model_path))\n",
    "except Exception:\n",
    "    print('TensorFlow/Keras unavailable; proceeding without classification.')\n",
    "    model = None\n",
    "\n",
    "lines = []\n",
    "for p in files:\n",
    "    bgr = cv2.imread(str(p))\n",
    "    if bgr is None:\n",
    "        msg = f'{p.name}: [unreadable]'\n",
    "        print(msg); lines.append(msg); continue\n",
    "\n",
    "    # Detect and warp\n",
    "    corners = None\n",
    "    try:\n",
    "        corners = detect_paper_corners(bgr)\n",
    "    except Exception:\n",
    "        corners = None\n",
    "    warped = warp_to_a4(bgr, corners) if corners is not None else bgr\n",
    "\n",
    "    # Binarize and components\n",
    "    bin_img = binarize(warped)\n",
    "    boxes = extract_components(bin_img)\n",
    "\n",
    "    # Prepare patches and classify (optional)\n",
    "    preds = None\n",
    "    if boxes:\n",
    "        patches28 = np.stack([crop_and_resize(warped, b, 28) for b in boxes], axis=0).astype(np.uint8)\n",
    "        if model is not None:\n",
    "            try:\n",
    "                preds = predict_digits(model, patches28)\n",
    "            except Exception:\n",
    "                preds = None\n",
    "\n",
    "    # Compose output line\n",
    "    if preds is None:\n",
    "        if boxes:\n",
    "            msg = f'{p.name}: components={len(boxes)} (classification disabled)'\n",
    "        else:\n",
    "            msg = f'{p.name}: []'\n",
    "    else:\n",
    "        seq = ''.join(map(str, preds.tolist()))\n",
    "        msg = f'{p.name}: {seq}'\n",
    "    print(msg); lines.append(msg)\n",
    "\n",
    "    # Save overlay (boxes + optional labels)\n",
    "    try:\n",
    "        vis = warped.copy()\n",
    "        for i, (x, y, w, h) in enumerate(boxes):\n",
    "            cv2.rectangle(vis, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            if preds is not None:\n",
    "                cv2.putText(vis, str(int(preds[i])), (x, max(0, y-5)),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "        cv2.imwrite(str(out_dir / f'{p.stem}_overlay.jpg'), vis)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Save grid of 28x28 crops\n",
    "    try:\n",
    "        if boxes:\n",
    "            n = len(boxes); cols = min(8, n); rows = int(np.ceil(n / cols))\n",
    "            fig, axes = plt.subplots(rows, cols, figsize=(1.4*cols, 1.4*rows))\n",
    "            axes = np.atleast_2d(axes)\n",
    "            k = 0\n",
    "            for r in range(rows):\n",
    "                for c in range(cols):\n",
    "                    ax = axes[r, c] if rows > 1 or cols > 1 else axes[0, 0]\n",
    "                    ax.axis('off')\n",
    "                    if k < n:\n",
    "                        ax.imshow(patches28[k], cmap='gray', vmin=0, vmax=255)\n",
    "                        if preds is not None:\n",
    "                            ax.set_title(str(int(preds[k])), fontsize=9)\n",
    "                        k += 1\n",
    "            plt.tight_layout()\n",
    "            fig.savefig(out_dir / f'{p.stem}_grid.jpg', dpi=150)\n",
    "            plt.close(fig)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Save results file\n",
    "(results_txt := out_dir / 'results.txt').write_text('\\n'.join(lines))\n",
    "print(f'Saved results to: {results_txt}')\n",
    "print(f'Overlays and grids in: {out_dir}')"
   ],
   "id": "d9c5bdb8aa31f181",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Evaluate images1 and images2 (if present), print per-file results, and save per-set CSV summaries to HW_1/results\n",
    "from pathlib import Path\n",
    "import sys, importlib, csv\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "# Make 'src' importable as a package\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "\n",
    "import src.pipeline as pipeline\n",
    "import src.model as model_mod\n",
    "\n",
    "# Reload to pick up latest src edits (corner fixes, etc.)\n",
    "importlib.reload(pipeline)\n",
    "importlib.reload(model_mod)\n",
    "\n",
    "sets = [ROOT / 'images1', ROOT / 'images2']\n",
    "sets = [d for d in sets if d.exists()]\n",
    "\n",
    "assert sets, 'No images1/ or images2/ directories found.'\n",
    "\n",
    "# Load or train model once (skip classification if TF unavailable)\n",
    "model_path = ROOT / 'HW_1' / 'model.h5'\n",
    "try:\n",
    "    model = model_mod.load_or_train_default(str(model_path))\n",
    "except Exception:\n",
    "    print('TensorFlow/Keras unavailable; proceeding without classification.')\n",
    "    model = None\n",
    "\n",
    "out_dir = ROOT / 'HW_1' / 'results'\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def collect_files(d):\n",
    "    files = []\n",
    "    for ext in ('*.jpg','*.jpeg','*.png','*.JPG','*.PNG'):\n",
    "        files += sorted(d.glob(ext))\n",
    "    return files\n",
    "\n",
    "for d in sets:\n",
    "    files = collect_files(d)\n",
    "    if not files:\n",
    "        print(f'No images in {d}')\n",
    "        continue\n",
    "\n",
    "    print(f'\\n=== Processing: {d.name} ({len(files)} images) ===')\n",
    "    lines = []\n",
    "    stats = {'total': len(files), 'unreadable': 0, 'no_paper': 0, 'empty': 0, 'classified': 0, 'components_only': 0}\n",
    "\n",
    "    for p in files:\n",
    "        s = pipeline.process_image(p, model, model_path)\n",
    "        print(s)\n",
    "        lines.append(s)\n",
    "\n",
    "        # crude status parsing\n",
    "        if '[unreadable]' in s:\n",
    "            stats['unreadable'] += 1\n",
    "        elif '[paper not found]' in s:\n",
    "            stats['no_paper'] += 1\n",
    "        elif s.endswith(': []'):\n",
    "            stats['empty'] += 1\n",
    "        elif 'components=' in s:\n",
    "            stats['components_only'] += 1\n",
    "        else:\n",
    "            stats['classified'] += 1\n",
    "\n",
    "    # Save CSV summary\n",
    "    csv_path = out_dir / f'results_{d.name}.csv'\n",
    "    with csv_path.open('w', newline='') as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow(['filename', 'result'])\n",
    "        for s in lines:\n",
    "            if ': ' in s:\n",
    "                name, res = s.split(': ', 1)\n",
    "            else:\n",
    "                name, res = s, ''\n",
    "            w.writerow([name, res])\n",
    "\n",
    "    # Print brief summary\n",
    "    print(f'\\nSummary for {d.name}:')\n",
    "    print(f\"  total={stats['total']}, unreadable={stats['unreadable']}, no_paper={stats['no_paper']}, empty={stats['empty']},\")\n",
    "    print(f\"  components_only={stats['components_only']}, classified={stats['classified']}\")\n",
    "    print(f'Saved CSV: {csv_path}')"
   ],
   "id": "c4f527c80cd5fd42",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Failure analysis: show up to 3 hard cases (paper not found or no components) from images1/images2\n",
    "from pathlib import Path\n",
    "import sys, cv2, numpy as np, matplotlib.pyplot as plt\n",
    "\n",
    "# Make src importable\n",
    "ROOT = Path.cwd()\n",
    "for cand in (ROOT / 'src', ROOT / 'HW_1' / 'src'):\n",
    "    if (cand / '__init__.py').exists() and str(cand) not in sys.path:\n",
    "        sys.path.insert(0, str(cand))\n",
    "\n",
    "from paper_detect import detect_paper_corners, warp_to_a4\n",
    "from segments import binarize, extract_components\n",
    "\n",
    "def debug_show(p: Path):\n",
    "    bgr = cv2.imread(str(p))\n",
    "    if bgr is None:\n",
    "        print('Unreadable:', p.name); return\n",
    "    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
    "    v = np.median(gray); lo, hi = int(max(0, 0.66*v)), int(min(255, 1.33*v))\n",
    "    edges = cv2.Canny(gray, lo, hi)\n",
    "\n",
    "    corners = None\n",
    "    try:\n",
    "        corners = detect_paper_corners(bgr)\n",
    "    except Exception:\n",
    "        corners = None\n",
    "\n",
    "    vis0 = bgr.copy()\n",
    "    if corners is not None:\n",
    "        for (x, y) in corners.astype(int):\n",
    "            cv2.circle(vis0, (x, y), 6, (0, 0, 255), -1)\n",
    "\n",
    "    warped = warp_to_a4(bgr, corners) if corners is not None else bgr\n",
    "    bin_img = binarize(warped)\n",
    "    boxes = extract_components(bin_img)\n",
    "\n",
    "    vis_w = warped.copy()\n",
    "    for (x, y, w, h) in boxes:\n",
    "        cv2.rectangle(vis_w, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
    "    axes[0].imshow(cv2.cvtColor(vis0, cv2.COLOR_BGR2RGB)); axes[0].set_title(f'{p.name} + corners'); axes[0].axis('off')\n",
    "    axes[1].imshow(edges, cmap='gray'); axes[1].set_title('Edges'); axes[1].axis('off')\n",
    "    axes[2].imshow(cv2.cvtColor(vis_w, cv2.COLOR_BGR2RGB)); axes[2].set_title(f'Warped + boxes ({len(boxes)})'); axes[2].axis('off')\n",
    "    plt.tight_layout()\n",
    "    status = 'OK' if corners is not None and len(boxes) > 0 else ('no_paper' if corners is None else 'no_components')\n",
    "    print(f'{p.name}: {status}')\n",
    "\n",
    "def collect_files(d):\n",
    "    files = []\n",
    "    for ext in ('*.jpg','*.jpeg','*.png','*.JPG','*.PNG'):\n",
    "        files += sorted(d.glob(ext))\n",
    "    return files\n",
    "\n",
    "candidates = []\n",
    "for d in (ROOT / 'images1', ROOT / 'images2'):\n",
    "    if d.exists():\n",
    "        candidates += collect_files(d)\n",
    "\n",
    "shown = 0\n",
    "for p in candidates:\n",
    "    # quick probe to pick failures\n",
    "    bgr = cv2.imread(str(p))\n",
    "    if bgr is None:\n",
    "        continue\n",
    "    try:\n",
    "        c = detect_paper_corners(bgr)\n",
    "        warped = warp_to_a4(bgr, c) if c is not None else bgr\n",
    "        boxes = extract_components(binarize(warped))\n",
    "        is_fail = (c is None) or (len(boxes) == 0)\n",
    "    except Exception:\n",
    "        is_fail = True\n",
    "    if is_fail:\n",
    "        debug_show(p); shown += 1\n",
    "        if shown >= 3:\n",
    "            break\n",
    "\n",
    "if shown == 0 and candidates:\n",
    "    print('No obvious failures found; showing two successes for reference.')\n",
    "    for p in candidates[:2]:\n",
    "        debug_show(p)"
   ],
   "id": "4f4959a22602144e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
