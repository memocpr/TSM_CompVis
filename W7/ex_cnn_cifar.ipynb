{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Image Classification with larger CNN\n",
    "\n",
    "The goal of this exercise is to program a slightly larger CNN that incorporates some of the ideas that have been presented in the class. We use CIFAR-100, which is a bit more challenging than the MNIST data set, but not so much. It contains 50000 images that are labelled into 100 fine-grained classes of 20 more coarse grained classes. In order to make the task a mit more complicated we will use the fine grained classes.\n",
    "\n",
    "The dataset is build into keras."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "import keras\n",
    "import keras.datasets\n",
    "import keras.datasets.cifar100\n",
    "import keras.utils\n",
    "import keras.optimizers\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(keras.__version__)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar100.load_data()\n",
    "assert x_train.shape == (50000, 32, 32, 3)\n",
    "assert x_test.shape == (10000, 32, 32, 3)\n",
    "assert y_train.shape == (50000, 1)\n",
    "assert y_test.shape == (10000, 1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    index = np.random.randint(50000)\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(np.array(x_train[index]).astype(\"uint8\"))\n",
    "    plt.title(int(y_train[index]))\n",
    "    plt.axis(\"off\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "num_classes = 100\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ResNet-style model with skip connections (Exercise 1) + Batch Normalization\n",
    "def build_model():\n",
    "    inp = keras.Input(shape=(32, 32, 3))\n",
    "\n",
    "    def residual(x, filters, stride=1):\n",
    "        shortcut = x\n",
    "        # Conv -> BN -> ReLU\n",
    "        y = keras.layers.Conv2D(filters, 3, strides=stride, padding='same', use_bias=False)(x)\n",
    "        y = keras.layers.BatchNormalization()(y)\n",
    "        y = keras.layers.Activation('relu')(y)\n",
    "        # Conv -> BN\n",
    "        y = keras.layers.Conv2D(filters, 3, padding='same', use_bias=False)(y)\n",
    "        y = keras.layers.BatchNormalization()(y)\n",
    "        # projection on shortcut when shape changes\n",
    "        if stride != 1 or shortcut.shape[-1] != filters:\n",
    "            shortcut = keras.layers.Conv2D(filters, 1, strides=stride, padding='same', use_bias=False)(shortcut)\n",
    "            shortcut = keras.layers.BatchNormalization()(shortcut)\n",
    "        out = keras.layers.Add()([y, shortcut])\n",
    "        out = keras.layers.Activation('relu')(out)\n",
    "        return out\n",
    "\n",
    "    # Stem: Conv -> BN -> ReLU\n",
    "    x = keras.layers.Conv2D(32, 3, padding='same', use_bias=False)(inp)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.Activation('relu')(x)\n",
    "\n",
    "    # stage 1\n",
    "    x = residual(x, 32)\n",
    "    x = residual(x, 32)\n",
    "    # stage 2 (downsample)\n",
    "    x = residual(x, 64, stride=2)\n",
    "    x = residual(x, 64)\n",
    "    # stage 3 (downsample)\n",
    "    x = residual(x, 128, stride=2)\n",
    "    x = residual(x, 128)\n",
    "\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Dense(100, activation='softmax')(x)\n",
    "\n",
    "    return keras.Model(inp, x)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model = build_model()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "model.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "batch_size = 128\n",
    "epochs = 5\n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.01)\n",
    "model = build_model()\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance is not bad, but also not so great. The best results without using additional data for convolutional neural networks is at about 70 percent."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(history.history)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(history.history['accuracy'], label='acc')\n",
    "ax.plot( history.history['val_accuracy'], label='v_acc')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Modern CNN\n",
    "\n",
    "A *modern* CNN should have some of the features discussed in the lecture. Build a model that includes some or all of these:\n",
    "- ResNet architecture with skip connections\n",
    "- Batch Normalization\n",
    "- L2 Regularisation\n",
    "- Dropout\n",
    "\n",
    "How does you model perform?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Monitoring\n",
    "\n",
    "Monitoring the training is essential for long running training sessions. Include tensorboard or wandb in your training setup."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Data Augmentation (continued next lesson)\n",
    "\n",
    "What else could be done to get better results? The dataset is quite small, so either another dataset could be used for pretraining, or data augmentation could be added...."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
